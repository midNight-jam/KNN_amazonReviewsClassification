{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "columns=['label','document']\n",
    "\n",
    "def replace_special_character(document):\n",
    "    result = re.sub('[^a-zA-Z\\n\\.]', ' ', document).replace(\".\", \"\")\n",
    "    result = ' '.join(result.split())\n",
    "    result = \"\".join(result.splitlines())\n",
    "    result=re.sub(r'\\b\\w{1,3}\\b', '', result)\n",
    "    return result.strip()\n",
    "\n",
    "def removestopword(document):\n",
    "    text = ' '.join([word for word in document.lower().split() if word not in cachedStopWords])\n",
    "    return text\n",
    "\n",
    "\n",
    "docIdLable = {}\n",
    "def readdocument():\n",
    "    data=[]\n",
    "    files = [\"data/train.dat\"]\n",
    "    for f in files:\n",
    "        with open(f) as fl:\n",
    "            idx = 0\n",
    "            for lines in fl:\n",
    "                temp=[lines[:2],lines[3:].strip(\" \")]\n",
    "                data.append(temp)\n",
    "                docIdLable[idx] = lines[:2]\n",
    "                idx +=1\n",
    "    df=pd.DataFrame(data,columns=columns)\n",
    "    df['document'] = df['document'].apply(lambda x: removestopword(x))\n",
    "    df['document'] = df['document'].apply(lambda x: replace_special_character(x))\n",
    "    vectorizer = CountVectorizer(min_df=1, max_features=2000)\n",
    "    X = vectorizer.fit_transform(df['document'].values)\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    tfidf=transformer.fit_transform(X)\n",
    "    return tfidf\n",
    "\n",
    "def readTestdocument(location):\n",
    "    data=[]\n",
    "    with open(location) as fl:\n",
    "        for lines in fl:\n",
    "            temp=lines.strip(\" \")\n",
    "            data.append(temp)\n",
    "    df=pd.DataFrame(data,columns=['document'])\n",
    "    df['document'] = df['document'].apply(lambda x: removestopword(x))\n",
    "    df['document'] = df['document'].apply(lambda x: replace_special_character(x))\n",
    "    vectorizer = CountVectorizer(min_df=1, max_features=2000)\n",
    "    X = vectorizer.fit_transform(df['document'].values)\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    tfidf=transformer.fit_transform(X)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "def cosineSimilarity(d1,d2, id):\n",
    "    return 1 - spatial.distance.cosine(d1,d2)\n",
    "\n",
    "# function to calculate K closest neighbours\n",
    "import operator\n",
    "import itertools\n",
    "def kNearestNeighbours(trainVector, testVector, k):\n",
    "    allDistances = {}\n",
    "    for t in range(len(trainVector)):\n",
    "        dist = spatial.distance.cosine(trainVector[t],testVector)\n",
    "        allDistances[t] = dist\n",
    "    return [(k,allDistances[k]) for k in sorted(allDistances, key=lambda x:allDistances[x],reverse=True)][:k]\n",
    "\n",
    "# function to get predicted label based on the closest neighbours\n",
    "import random\n",
    "def getPredictedLabel(nearDocs):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    dict = {k:v for k,v in nearDocs} \n",
    "    for k in dict:\n",
    "        if docIdLable[k] == '+1':\n",
    "            pos+=1\n",
    "        else:\n",
    "            neg+=1\n",
    "    \n",
    "    genLab = None\n",
    "    if(pos==neg):\n",
    "        genLab =  random.sample(set([-1,1],1))\n",
    "    else: \n",
    "        genLab = '+1' if pos> neg else '-1'\n",
    "    print(\"calculated Label : \", genLab)\n",
    "    return genLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train doc read completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test doc read completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated Label :  +1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-12ad80b2ae73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mgenLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"  calculated Label : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "finalTrainTf = readdocument()\n",
    "print(\"train doc read completed\")\n",
    "finalTestTf = readTestdocument(\"data/test.dat\")\n",
    "print(\"test doc read completed\")\n",
    "finalTrainTfArr = finalTrainTf.toarray()\n",
    "finalTestTfArr = finalTestTf.toarray()\n",
    "\n",
    "\n",
    "genLabels = []\n",
    "k = 5\n",
    "f = open('genLabels','w')\n",
    "for tes in finalTestTfArr:\n",
    "    nearest = kNearestNeighbours(finalTrainTfArr,tes,k)\n",
    "    lab = getPredictedLabel(nearest)\n",
    "    f.write(lab+\"\\n\")\n",
    "    genLabels.append(lab)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}